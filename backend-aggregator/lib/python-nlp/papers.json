[
    {"title": "On the Global Convergence of Training Deep Linear ResNets", "submission_date": "Mon, 2 Mar 2020 18:34:49 UTC", "authors": ["Difan Zou", "Philip M. Long", "Quanquan Gu"], "pdf_link": "https://arxiv.org/pdf/2003.01094.pdf", "abstract": "<blockquote class=\"abstract mathjax\"><span class=\"descriptor\">Abstract:</span>  We study the convergence of gradient descent (GD) and stochastic gradient\ndescent (SGD) for training $L$-hidden-layer linear residual networks (ResNets).\nWe prove that for training deep residual networks with certain linear\ntransformations at input and output layers, which are fixed throughout\ntraining, both GD and SGD with zero initialization on all hidden weights can\nconverge to the global minimum of the training loss. Moreover, when\nspecializing to appropriate Gaussian random linear transformations, GD and SGD\nprovably optimize wide enough deep linear ResNets. Compared with the global\nconvergence result of GD for training standard deep linear networks (Du &amp; Hu\n2019), our condition on the neural network width is sharper by a factor of\n$O(\\kappa L)$, where $\\kappa$ denotes the condition number of the covariance\nmatrix of the training data. We further propose a modified identity input and\noutput transformations, and show that a $(d+k)$-wide neural network is\nsufficient to guarantee the global convergence of GD/SGD, where $d,k$ are the\ninput and output dimensions respectively.\n</blockquote>", "abstract_text": "  We study the convergence of gradient descent (GD) and stochastic gradient\ndescent (SGD) for training $L$-hidden-layer linear residual networks (ResNets).\nWe prove that for training deep residual networks with certain linear\ntransformations at input and output layers, which are fixed throughout\ntraining, both GD and SGD with zero initialization on all hidden weights can\nconverge to the global minimum of the training loss. Moreover, when\nspecializing to appropriate Gaussian random linear transformations, GD and SGD\nprovably optimize wide enough deep linear ResNets. Compared with the global\nconvergence result of GD for training standard deep linear networks (Du & Hu\n2019), our condition on the neural network width is sharper by a factor of\n$O(\\kappa L)$, where $\\kappa$ denotes the condition number of the covariance\nmatrix of the training data. We further propose a modified identity input and\noutput transformations, and show that a $(d+k)$-wide neural network is\nsufficient to guarantee the global convergence of GD/SGD, where $d,k$ are the\ninput and output dimensions respectively.\n"},
    {"title": "Double Trouble in Double Descent : Bias and Variance(s) in the Lazy Regime", "submission_date": "Mon, 2 Mar 2020 17:39:31 UTC", "authors": ["St\u00e9phane d'Ascoli", "Maria Refinetti", "Giulio Biroli", "Florent Krzakala"], "pdf_link": "https://arxiv.org/pdf/2003.01054.pdf", "abstract": "<blockquote class=\"abstract mathjax\"><span class=\"descriptor\">Abstract:</span>  Deep neural networks can achieve remarkable generalization performances while\ninterpolating the training data perfectly. Rather than the U-curve emblematic\nof the bias-variance trade-off, their test error often follows a double descent\n- a mark of the beneficial role of overparametrization. In this work, we\ndevelop a quantitative theory for this phenomenon in the so-called lazy\nlearning regime of neural networks, by considering the problem of learning a\nhigh-dimensional function with random features regression. We obtain a precise\nasymptotic expression for the bias-variance decomposition of the test error,\nand show that the bias displays a phase transition at the interpolation\nthreshold, beyond it which it remains constant. We disentangle the variances\nstemming from the sampling of the dataset, from the additive noise corrupting\nthe labels, and from the initialization of the weights. Following Geiger et\nal., we first show that the latter two contributions are the crux of the double\ndescent: they lead to the overfitting peak at the interpolation threshold and\nto the decay of the test error upon overparametrization. We then quantify how\nthey are suppressed by ensembling the outputs of K independently initialized\nestimators. When K is sent to infinity, the test error remains constant beyond\nthe interpolation threshold. We further compare the effects of\noverparametrizing, ensembling and regularizing. Finally, we present numerical\nexperiments on classic deep learning setups to show that our results hold\nqualitatively in realistic lazy learning scenarios.\n</blockquote>", "abstract_text": "  Deep neural networks can achieve remarkable generalization performances while\ninterpolating the training data perfectly. Rather than the U-curve emblematic\nof the bias-variance trade-off, their test error often follows a double descent\n- a mark of the beneficial role of overparametrization. In this work, we\ndevelop a quantitative theory for this phenomenon in the so-called lazy\nlearning regime of neural networks, by considering the problem of learning a\nhigh-dimensional function with random features regression. We obtain a precise\nasymptotic expression for the bias-variance decomposition of the test error,\nand show that the bias displays a phase transition at the interpolation\nthreshold, beyond it which it remains constant. We disentangle the variances\nstemming from the sampling of the dataset, from the additive noise corrupting\nthe labels, and from the initialization of the weights. Following Geiger et\nal., we first show that the latter two contributions are the crux of the double\ndescent: they lead to the overfitting peak at the interpolation threshold and\nto the decay of the test error upon overparametrization. We then quantify how\nthey are suppressed by ensembling the outputs of K independently initialized\nestimators. When K is sent to infinity, the test error remains constant beyond\nthe interpolation threshold. We further compare the effects of\noverparametrizing, ensembling and regularizing. Finally, we present numerical\nexperiments on classic deep learning setups to show that our results hold\nqualitatively in realistic lazy learning scenarios.\n"},
    {"title": "Bridging the Gap Between Theory and Practice on Insertion-Intensive Database", "submission_date": "Mon, 2 Mar 2020 17:50:07 UTC", "authors": ["Sepanta Zeighami", "Raymond Chi-Wing Wong"], "pdf_link": "https://arxiv.org/pdf/2003.01064.pdf", "abstract": "<blockquote class=\"abstract mathjax\"><span class=\"descriptor\">Abstract:</span>  With the prevalence of online platforms, today, data is being generated and\naccessed by users at a very high rate. Besides, applications such as stock\ntrading or high frequency trading require guaranteed low delays for performing\nan operation on a database. It is consequential to design databases that\nguarantee data insertion and query at a consistently high rate without\nintroducing any long delay during insertion. In this paper, we propose Nested\nB-trees (NB-trees), an index that can achieve a consistently high insertion\nrate on large volumes of data, while providing asymptotically optimal query\nperformance that is very efficient in practice. Nested B-trees support\ninsertions at rates higher than LSM-trees, the state-of-the-art index for\ninsertion-intensive workloads, while avoiding their long insertion delays and\nimproving on their query performance. They approach the query performance of\nB-trees when complemented with Bloom filters. In our experiments, NB-trees had\nworst-case delays up to 1000 smaller than LevelDB, RocksDB and bLSM, commonly\nused LSM-tree data-stores, could perform queries more than 4 times faster than\nLevelDB and 1.5 times faster than bLSM and RocksDB, while also outperforming\nthem in terms of average insertion rate.\n</blockquote>", "abstract_text": "  With the prevalence of online platforms, today, data is being generated and\naccessed by users at a very high rate. Besides, applications such as stock\ntrading or high frequency trading require guaranteed low delays for performing\nan operation on a database. It is consequential to design databases that\nguarantee data insertion and query at a consistently high rate without\nintroducing any long delay during insertion. In this paper, we propose Nested\nB-trees (NB-trees), an index that can achieve a consistently high insertion\nrate on large volumes of data, while providing asymptotically optimal query\nperformance that is very efficient in practice. Nested B-trees support\ninsertions at rates higher than LSM-trees, the state-of-the-art index for\ninsertion-intensive workloads, while avoiding their long insertion delays and\nimproving on their query performance. They approach the query performance of\nB-trees when complemented with Bloom filters. In our experiments, NB-trees had\nworst-case delays up to 1000 smaller than LevelDB, RocksDB and bLSM, commonly\nused LSM-tree data-stores, could perform queries more than 4 times faster than\nLevelDB and 1.5 times faster than bLSM and RocksDB, while also outperforming\nthem in terms of average insertion rate.\n"},
    {"title": "A Feature-aware SPH for Isotropic Unstructured Mesh Generation", "submission_date": "Thu, 27 Feb 2020 13:35:07 UTC", "authors": ["Zhe Ji", "Lin Fu", "Xiangyu Hu", "Nikolaus Adams"], "pdf_link": "https://arxiv.org/pdf/2003.01061.pdf", "abstract": "<blockquote class=\"abstract mathjax\"><span class=\"descriptor\">Abstract:</span>  In this paper, we present a feature-aware SPH method for the concurrent and\nautomated isotropic unstructured mesh generation. Two additional objectives are\nachieved with the proposed method compared to the original SPH-based mesh\ngenerator (Fu et al., 2019). First, a feature boundary correction term is\nintroduced to address the issue of incomplete kernel support at the boundary\nvicinity. The mesh generation of feature curves, feature surfaces and volumes\ncan be handled concurrently without explicitly following a dimensional\nsequence. Second, a two-phase model is proposed to characterize the\nmesh-generation procedure by a feature-size-adaptation phase and a\nmesh-quality-optimization phase. By proposing a new error measurement criterion\nand an adaptive control system with two sets of simulation parameters, the\nobjectives of faster feature-size adaptation and local mesh-quality improvement\nare merged into a consistent framework. The proposed method is validated with a\nset of 2D and 3D numerical tests with different complexities and scales. The\nresults demonstrate that high-quality meshes are generated with a significant\nspeedup of convergence.\n</blockquote>", "abstract_text": "  In this paper, we present a feature-aware SPH method for the concurrent and\nautomated isotropic unstructured mesh generation. Two additional objectives are\nachieved with the proposed method compared to the original SPH-based mesh\ngenerator (Fu et al., 2019). First, a feature boundary correction term is\nintroduced to address the issue of incomplete kernel support at the boundary\nvicinity. The mesh generation of feature curves, feature surfaces and volumes\ncan be handled concurrently without explicitly following a dimensional\nsequence. Second, a two-phase model is proposed to characterize the\nmesh-generation procedure by a feature-size-adaptation phase and a\nmesh-quality-optimization phase. By proposing a new error measurement criterion\nand an adaptive control system with two sets of simulation parameters, the\nobjectives of faster feature-size adaptation and local mesh-quality improvement\nare merged into a consistent framework. The proposed method is validated with a\nset of 2D and 3D numerical tests with different complexities and scales. The\nresults demonstrate that high-quality meshes are generated with a significant\nspeedup of convergence.\n"},
    {"title": "Gaussian Process Policy Optimization", "submission_date": "Mon, 2 Mar 2020 18:06:27 UTC", "authors": ["Ashish Rao", "Bidipta Sarkar", "Tejas Narayanan"], "pdf_link": "https://arxiv.org/pdf/2003.01074.pdf", "abstract": "<blockquote class=\"abstract mathjax\"><span class=\"descriptor\">Abstract:</span>  We propose a novel actor-critic, model-free reinforcement learning algorithm\nwhich employs a Bayesian method of parameter space exploration to solve\nenvironments. A Gaussian process is used to learn the expected return of a\npolicy given the policy's parameters. The system is trained by updating the\nparameters using gradient descent on a new surrogate loss function consisting\nof the Proximal Policy Optimization 'Clipped' loss function and a bonus term\nrepresenting the expected improvement acquisition function given by the\nGaussian process. This new method is shown to be comparable to and at times\nempirically outperform current algorithms on environments that simulate robotic\nlocomotion using the MuJoCo physics engine.\n</blockquote>", "abstract_text": "  We propose a novel actor-critic, model-free reinforcement learning algorithm\nwhich employs a Bayesian method of parameter space exploration to solve\nenvironments. A Gaussian process is used to learn the expected return of a\npolicy given the policy's parameters. The system is trained by updating the\nparameters using gradient descent on a new surrogate loss function consisting\nof the Proximal Policy Optimization 'Clipped' loss function and a bonus term\nrepresenting the expected improvement acquisition function given by the\nGaussian process. This new method is shown to be comparable to and at times\nempirically outperform current algorithms on environments that simulate robotic\nlocomotion using the MuJoCo physics engine.\n"},
    {"title": "D3VO: Deep Depth, Deep Pose and Deep Uncertainty for Monocular Visual Odometry", "submission_date": "Mon, 2 Mar 2020 17:47:13 UTC", "authors": ["Nan Yang", "Lukas von Stumberg", "Rui Wang", "Daniel Cremers"], "pdf_link": "https://arxiv.org/pdf/2003.01060.pdf", "abstract": "<blockquote class=\"abstract mathjax\"><span class=\"descriptor\">Abstract:</span>  We propose D3VO as a novel framework for monocular visual odometry that\nexploits deep networks on three levels -- deep depth, pose and uncertainty\nestimation. We first propose a novel self-supervised monocular depth estimation\nnetwork trained on stereo videos without any external supervision. In\nparticular, it aligns the training image pairs into similar lighting condition\nwith predictive brightness transformation parameters. Besides, we model the\nphotometric uncertainties of pixels on the input images, which improves the\ndepth estimation accuracy and provides a learned weighting function for the\nphotometric residuals in direct (feature-less) visual odometry. Evaluation\nresults show that the proposed network outperforms state-of-the-art\nself-supervised depth estimation networks. D3VO tightly incorporates the\npredicted depth, pose and uncertainty into a direct visual odometry method to\nboost both the front-end tracking as well as the back-end non-linear\noptimization. We evaluate D3VO in terms of monocular visual odometry on both\nthe KITTI odometry benchmark and the EuRoC MAV dataset. The results show that\nD3VO outperforms state-of-the-art traditional monocular VO methods by a large\nmargin. It also achieves comparable results to state-of-the-art stereo/LiDAR\nodometry on KITTI and to the state-of-the-art visual-inertial odometry on EuRoC\nMAV, while using only a single camera.\n</blockquote>", "abstract_text": "  We propose D3VO as a novel framework for monocular visual odometry that\nexploits deep networks on three levels -- deep depth, pose and uncertainty\nestimation. We first propose a novel self-supervised monocular depth estimation\nnetwork trained on stereo videos without any external supervision. In\nparticular, it aligns the training image pairs into similar lighting condition\nwith predictive brightness transformation parameters. Besides, we model the\nphotometric uncertainties of pixels on the input images, which improves the\ndepth estimation accuracy and provides a learned weighting function for the\nphotometric residuals in direct (feature-less) visual odometry. Evaluation\nresults show that the proposed network outperforms state-of-the-art\nself-supervised depth estimation networks. D3VO tightly incorporates the\npredicted depth, pose and uncertainty into a direct visual odometry method to\nboost both the front-end tracking as well as the back-end non-linear\noptimization. We evaluate D3VO in terms of monocular visual odometry on both\nthe KITTI odometry benchmark and the EuRoC MAV dataset. The results show that\nD3VO outperforms state-of-the-art traditional monocular VO methods by a large\nmargin. It also achieves comparable results to state-of-the-art stereo/LiDAR\nodometry on KITTI and to the state-of-the-art visual-inertial odometry on EuRoC\nMAV, while using only a single camera.\n"},
    {"title": "Learning from Positive and Unlabeled Data by Identifying the Annotation Process", "submission_date": "Mon, 2 Mar 2020 17:57:12 UTC", "authors": ["Naji Shajarisales", "Peter Spirtes", "Kun Zhang"], "pdf_link": "https://arxiv.org/pdf/2003.01067.pdf", "abstract": "<blockquote class=\"abstract mathjax\"><span class=\"descriptor\">Abstract:</span>  In binary classification, Learning from Positive and Unlabeled data (LePU) is\nsemi-supervised learning but with labeled elements from only one class. Most of\nthe research on LePU relies on some form of independence between the selection\nprocess of annotated examples and the features of the annotated class, known as\nthe Selected Completely At Random (SCAR) assumption. Yet the annotation process\nis an important part of the data collection, and in many cases it naturally\ndepends on certain features of the data (e.g., the intensity of an image and\nthe size of the object to be detected in the image). Without any constraints on\nthe model for the annotation process, classification results in the LePU\nproblem will be highly non-unique. So proper, flexible constraints are needed.\nIn this work we incorporate more flexible and realistic models for the\nannotation process than SCAR, and more importantly, offer a solution for the\nchallenging LePU problem. On the theory side, we establish the identifiability\nof the properties of the annotation process and the classification function, in\nlight of the considered constraints on the data-generating process. We also\npropose an inference algorithm to learn the parameters of the model, with\nsuccessful experimental results on both simulated and real data. We also\npropose a novel real-world dataset forLePU, as a benchmark dataset for future\nstudies.\n</blockquote>", "abstract_text": "  In binary classification, Learning from Positive and Unlabeled data (LePU) is\nsemi-supervised learning but with labeled elements from only one class. Most of\nthe research on LePU relies on some form of independence between the selection\nprocess of annotated examples and the features of the annotated class, known as\nthe Selected Completely At Random (SCAR) assumption. Yet the annotation process\nis an important part of the data collection, and in many cases it naturally\ndepends on certain features of the data (e.g., the intensity of an image and\nthe size of the object to be detected in the image). Without any constraints on\nthe model for the annotation process, classification results in the LePU\nproblem will be highly non-unique. So proper, flexible constraints are needed.\nIn this work we incorporate more flexible and realistic models for the\nannotation process than SCAR, and more importantly, offer a solution for the\nchallenging LePU problem. On the theory side, we establish the identifiability\nof the properties of the annotation process and the classification function, in\nlight of the considered constraints on the data-generating process. We also\npropose an inference algorithm to learn the parameters of the model, with\nsuccessful experimental results on both simulated and real data. We also\npropose a novel real-world dataset forLePU, as a benchmark dataset for future\nstudies.\n"},
    {"title": "ProxEmo: Gait-based Emotion Learning and Multi-view Proxemic Fusion for Socially-Aware Robot Navigation", "submission_date": "Mon, 2 Mar 2020 17:47:49 UTC", "authors": ["Venkatraman Narayanan", "Bala Murali Manoghar", "Vishnu Sashank Dorbala", "Dinesh Manocha", "Aniket Bera"], "pdf_link": "https://arxiv.org/pdf/2003.01062.pdf", "abstract": "<blockquote class=\"abstract mathjax\"><span class=\"descriptor\">Abstract:</span>  We present ProxEmo, a novel end-to-end emotion prediction algorithm for\nsocially aware robot navigation among pedestrians. Our approach predicts the\nperceived emotions of a pedestrian from walking gaits, which is then used for\nemotion-guided navigation taking into account social and proxemic constraints.\nTo classify emotions, we propose a multi-view skeleton graph convolution-based\nmodel that works on a commodity camera mounted onto a moving robot. Our emotion\nrecognition is integrated into a mapless navigation scheme and makes no\nassumptions about the environment of pedestrian motion. It achieves a mean\naverage emotion prediction precision of 82.47% on the Emotion-Gait benchmark\ndataset. We outperform current state-of-art algorithms for emotion recognition\nfrom 3D gaits. We highlight its benefits in terms of navigation in indoor\nscenes using a Clearpath Jackal robot.\n</blockquote>", "abstract_text": "  We present ProxEmo, a novel end-to-end emotion prediction algorithm for\nsocially aware robot navigation among pedestrians. Our approach predicts the\nperceived emotions of a pedestrian from walking gaits, which is then used for\nemotion-guided navigation taking into account social and proxemic constraints.\nTo classify emotions, we propose a multi-view skeleton graph convolution-based\nmodel that works on a commodity camera mounted onto a moving robot. Our emotion\nrecognition is integrated into a mapless navigation scheme and makes no\nassumptions about the environment of pedestrian motion. It achieves a mean\naverage emotion prediction precision of 82.47% on the Emotion-Gait benchmark\ndataset. We outperform current state-of-art algorithms for emotion recognition\nfrom 3D gaits. We highlight its benefits in terms of navigation in indoor\nscenes using a Clearpath Jackal robot.\n"},
    {"title": "Constant delay enumeration with FPT-preprocessing for conjunctive queries of bounded submodular width", "submission_date": "Mon, 2 Mar 2020 18:09:43 UTC", "authors": ["Christoph Berkholz", "Nicole Schweikardt"], "pdf_link": "https://arxiv.org/pdf/2003.01075.pdf", "abstract": "<blockquote class=\"abstract mathjax\"><span class=\"descriptor\">Abstract:</span>  Marx (STOC~2010, J.~ACM 2013) introduced the notion of submodular width of a\nconjunctive query (CQ) and showed that for any class $\\Phi$ of Boolean CQs of\nbounded submodular width, the model-checking problem for $\\Phi$ on the class of\nall finite structures is fixed-parameter tractable (FPT). Note that for\nnon-Boolean queries, the size of the query result may be far too large to be\ncomputed entirely within FPT time. We investigate the free-connex variant of\nsubmodular width and generalise Marx's result to non-Boolean queries as\nfollows: For every class $\\Phi$ of CQs of bounded free-connex submodular width,\nwithin FPT-preprocessing time we can build a data structure that allows to\nenumerate, without repetition and with constant delay, all tuples of the query\nresult. Our proof builds upon Marx's splitting routine to decompose the query\nresult into a union of results; but we have to tackle the additional technical\ndifficulty to ensure that these can be enumerated efficiently.\n</blockquote>", "abstract_text": "  Marx (STOC~2010, J.~ACM 2013) introduced the notion of submodular width of a\nconjunctive query (CQ) and showed that for any class $\\Phi$ of Boolean CQs of\nbounded submodular width, the model-checking problem for $\\Phi$ on the class of\nall finite structures is fixed-parameter tractable (FPT). Note that for\nnon-Boolean queries, the size of the query result may be far too large to be\ncomputed entirely within FPT time. We investigate the free-connex variant of\nsubmodular width and generalise Marx's result to non-Boolean queries as\nfollows: For every class $\\Phi$ of CQs of bounded free-connex submodular width,\nwithin FPT-preprocessing time we can build a data structure that allows to\nenumerate, without repetition and with constant delay, all tuples of the query\nresult. Our proof builds upon Marx's splitting routine to decompose the query\nresult into a union of results; but we have to tackle the additional technical\ndifficulty to ensure that these can be enumerated efficiently.\n"},
    {"title": "Controller Tuning for Active Queue Management Using a Parameter Space Method", "submission_date": "Mon, 2 Mar 2020 18:09:47 UTC", "authors": ["Murat Saglam", "Sami Ezercan", "Suat Gumussoy", "Hitay Ozbay"], "pdf_link": "https://arxiv.org/pdf/2003.01076.pdf", "abstract": "<blockquote class=\"abstract mathjax\"><span class=\"descriptor\">Abstract:</span>  In recent years, different mathematical models have been proposed for widely\nused internet control mechanisms. Simple low order controllers (such as PID,\nand Smith predictor based linear controllers that are easy to implement) are\ndesired for network traffic management. In order to design such simple\ncontrollers for Active Queue Management (AQM), delay based linear models have\nbeen considered. In this paper we discuss tuning of the PID controllers by\nusing a parameter space method, which computes stability regions of a class of\nquasi-polynomials in terms of free controller parameters.\n</blockquote>", "abstract_text": "  In recent years, different mathematical models have been proposed for widely\nused internet control mechanisms. Simple low order controllers (such as PID,\nand Smith predictor based linear controllers that are easy to implement) are\ndesired for network traffic management. In order to design such simple\ncontrollers for Active Queue Management (AQM), delay based linear models have\nbeen considered. In this paper we discuss tuning of the PID controllers by\nusing a parameter space method, which computes stability regions of a class of\nquasi-polynomials in terms of free controller parameters.\n"},
    {"title": "On-the-fly Optimization of Parallel Computation of Symbolic Symplectic Invariants", "submission_date": "Mon, 2 Mar 2020 18:14:17 UTC", "authors": ["Joseph Ben Geloun", "Camille Coti", "Allen D. Malony"], "pdf_link": "https://arxiv.org/pdf/2003.01081.pdf", "abstract": "<blockquote class=\"abstract mathjax\"><span class=\"descriptor\">Abstract:</span>  Group invariants are used in high energy physics to define quantum field\ntheory interactions. In this paper, we are presenting the parallel algebraic\ncomputation of special invariants called symplectic and even focusing on one\nparticular invariant that finds recent interest in physics. Our results will\nexport to other invariants. The cost of performing basic computations on the\nmultivariate polynomials involved evolves during the computation, as the\npolynomials get larger or with an increasing number of terms. However, in some\ncases, they stay small. Traditionally, high-performance software is optimized\nby running it on a smaller data set in order to use profiling information to\nset some tuning parameters. Since the (communication and computation) costs\nevolve during the computation, the first iterations of the computation might\nnot be representative of the rest of the computation and this approach cannot\nbe applied in this case. To cope with this evolution, we are presenting an\napproach to get performance data and tune the algorithm during the execution.\n</blockquote>", "abstract_text": "  Group invariants are used in high energy physics to define quantum field\ntheory interactions. In this paper, we are presenting the parallel algebraic\ncomputation of special invariants called symplectic and even focusing on one\nparticular invariant that finds recent interest in physics. Our results will\nexport to other invariants. The cost of performing basic computations on the\nmultivariate polynomials involved evolves during the computation, as the\npolynomials get larger or with an increasing number of terms. However, in some\ncases, they stay small. Traditionally, high-performance software is optimized\nby running it on a smaller data set in order to use profiling information to\nset some tuning parameters. Since the (communication and computation) costs\nevolve during the computation, the first iterations of the computation might\nnot be representative of the rest of the computation and this approach cannot\nbe applied in this case. To cope with this evolution, we are presenting an\napproach to get performance data and tune the algorithm during the execution.\n"},
    {"title": "Predictive Coding for Locally-Linear Control", "submission_date": "Mon, 2 Mar 2020 18:20:41 UTC", "authors": ["Rui Shu", "Tung Nguyen", "Yinlam Chow", "Tuan Pham", "Khoat Than", "Mohammad Ghavamzadeh", "Stefano Ermon", "Hung H. Bui"], "pdf_link": "https://arxiv.org/pdf/2003.01086.pdf", "abstract": "<blockquote class=\"abstract mathjax\"><span class=\"descriptor\">Abstract:</span>  High-dimensional observations and unknown dynamics are major challenges when\napplying optimal control to many real-world decision making tasks. The Learning\nControllable Embedding (LCE) framework addresses these challenges by embedding\nthe observations into a lower dimensional latent space, estimating the latent\ndynamics, and then performing control directly in the latent space. To ensure\nthe learned latent dynamics are predictive of next-observations, all existing\nLCE approaches decode back into the observation space and explicitly perform\nnext-observation prediction---a challenging high-dimensional task that\nfurthermore introduces a large number of nuisance parameters (i.e., the\ndecoder) which are discarded during control. In this paper, we propose a novel\ninformation-theoretic LCE approach and show theoretically that explicit\nnext-observation prediction can be replaced with predictive coding. We then use\npredictive coding to develop a decoder-free LCE model whose latent dynamics are\namenable to locally-linear control. Extensive experiments on benchmark tasks\nshow that our model reliably learns a controllable latent space that leads to\nsuperior performance when compared with state-of-the-art LCE baselines.\n</blockquote>", "abstract_text": "  High-dimensional observations and unknown dynamics are major challenges when\napplying optimal control to many real-world decision making tasks. The Learning\nControllable Embedding (LCE) framework addresses these challenges by embedding\nthe observations into a lower dimensional latent space, estimating the latent\ndynamics, and then performing control directly in the latent space. To ensure\nthe learned latent dynamics are predictive of next-observations, all existing\nLCE approaches decode back into the observation space and explicitly perform\nnext-observation prediction---a challenging high-dimensional task that\nfurthermore introduces a large number of nuisance parameters (i.e., the\ndecoder) which are discarded during control. In this paper, we propose a novel\ninformation-theoretic LCE approach and show theoretically that explicit\nnext-observation prediction can be replaced with predictive coding. We then use\npredictive coding to develop a decoder-free LCE model whose latent dynamics are\namenable to locally-linear control. Extensive experiments on benchmark tasks\nshow that our model reliably learns a controllable latent space that leads to\nsuperior performance when compared with state-of-the-art LCE baselines.\n"},
    {"title": "Remarks on Strong Stabilization and Stable H-infinity Controller Design", "submission_date": "Mon, 2 Mar 2020 18:25:29 UTC", "authors": ["Suat Gumussoy", "Hitay Ozbay"], "pdf_link": "https://arxiv.org/pdf/2003.01089.pdf", "abstract": "<blockquote class=\"abstract mathjax\"><span class=\"descriptor\">Abstract:</span>  A state space based design method is given to find strongly stabilizing\ncontrollers for multi-input-multi-output plants (MIMO). A sufficient condition\nis derived for the existence of suboptimal stable H-infinity controller in\nterms of linear matrix inequalities (LMI) and the controller order is twice\nthat of the plant. A new parameterization of strongly stabilizing controllers\nis determined using linear fractional transformations (LFT).\n</blockquote>", "abstract_text": "  A state space based design method is given to find strongly stabilizing\ncontrollers for multi-input-multi-output plants (MIMO). A sufficient condition\nis derived for the existence of suboptimal stable H-infinity controller in\nterms of linear matrix inequalities (LMI) and the controller order is twice\nthat of the plant. A new parameterization of strongly stabilizing controllers\nis determined using linear fractional transformations (LFT).\n"},
    {"title": "Distributed Leader-Follower Formation Tracking Control of Multiple Quad-rotors", "submission_date": "Mon, 2 Mar 2020 18:18:54 UTC", "authors": ["Lixia Yan", "Baoli Ma"], "pdf_link": "https://arxiv.org/pdf/2003.01084.pdf", "abstract": "<blockquote class=\"abstract mathjax\"><span class=\"descriptor\">Abstract:</span>  The leader-follower formation control analysis for multiple quad-rotor\nsystems is investigated in this paper. To achieve predefined formation in the\nthree-dimensional air space ($x,y$ and $z$), a novel local tracking control law\nand a distributed observer are obtained. The local tracking control law starts\nwith finding a bounded continuous yet greater-than-zero control in $z$, based\non which following a feedback linearization controls derived for errors\nassociated with $x$ and $y$. The distributed observer achieves position\ncoordination among followers, though there are only partial followers can know\nthe leader's states and only neighboring communication is available. Simulation\nresults validate the proposed formation scheme.\n</blockquote>", "abstract_text": "  The leader-follower formation control analysis for multiple quad-rotor\nsystems is investigated in this paper. To achieve predefined formation in the\nthree-dimensional air space ($x,y$ and $z$), a novel local tracking control law\nand a distributed observer are obtained. The local tracking control law starts\nwith finding a bounded continuous yet greater-than-zero control in $z$, based\non which following a feedback linearization controls derived for errors\nassociated with $x$ and $y$. The distributed observer achieves position\ncoordination among followers, though there are only partial followers can know\nthe leader's states and only neighboring communication is available. Simulation\nresults validate the proposed formation scheme.\n"},
    {"title": "Learn2Perturb: an End-to-end Feature Perturbation Learning to Improve Adversarial Robustness", "submission_date": "Mon, 2 Mar 2020 18:27:35 UTC", "authors": ["Ahmadreza Jeddi", "Mohammad Javad Shafiee", "Michelle Karg", "Christian Scharfenberger", "Alexander Wong"], "pdf_link": "https://arxiv.org/pdf/2003.01090.pdf", "abstract": "<blockquote class=\"abstract mathjax\"><span class=\"descriptor\">Abstract:</span>  While deep neural networks have been achieving state-of-the-art performance\nacross a wide variety of applications, their vulnerability to adversarial\nattacks limits their widespread deployment for safety-critical applications.\nAlongside other adversarial defense approaches being investigated, there has\nbeen a very recent interest in improving adversarial robustness in deep neural\nnetworks through the introduction of perturbations during the training process.\nHowever, such methods leverage fixed, pre-defined perturbations and require\nsignificant hyper-parameter tuning that makes them very difficult to leverage\nin a general fashion. In this study, we introduce Learn2Perturb, an end-to-end\nfeature perturbation learning approach for improving the adversarial robustness\nof deep neural networks. More specifically, we introduce novel\nperturbation-injection modules that are incorporated at each layer to perturb\nthe feature space and increase uncertainty in the network. This feature\nperturbation is performed at both the training and the inference stages.\nFurthermore, inspired by the Expectation-Maximization, an alternating\nback-propagation training algorithm is introduced to train the network and\nnoise parameters consecutively. Experimental results on CIFAR-10 and CIFAR-100\ndatasets show that the proposed Learn2Perturb method can result in deep neural\nnetworks which are $4-7\\%$ more robust on $l_{\\infty}$ FGSM and PDG adversarial\nattacks and significantly outperforms the state-of-the-art against $l_2$ $C\\&amp;W$\nattack and a wide range of well-known black-box attacks.\n</blockquote>", "abstract_text": "  While deep neural networks have been achieving state-of-the-art performance\nacross a wide variety of applications, their vulnerability to adversarial\nattacks limits their widespread deployment for safety-critical applications.\nAlongside other adversarial defense approaches being investigated, there has\nbeen a very recent interest in improving adversarial robustness in deep neural\nnetworks through the introduction of perturbations during the training process.\nHowever, such methods leverage fixed, pre-defined perturbations and require\nsignificant hyper-parameter tuning that makes them very difficult to leverage\nin a general fashion. In this study, we introduce Learn2Perturb, an end-to-end\nfeature perturbation learning approach for improving the adversarial robustness\nof deep neural networks. More specifically, we introduce novel\nperturbation-injection modules that are incorporated at each layer to perturb\nthe feature space and increase uncertainty in the network. This feature\nperturbation is performed at both the training and the inference stages.\nFurthermore, inspired by the Expectation-Maximization, an alternating\nback-propagation training algorithm is introduced to train the network and\nnoise parameters consecutively. Experimental results on CIFAR-10 and CIFAR-100\ndatasets show that the proposed Learn2Perturb method can result in deep neural\nnetworks which are $4-7\\%$ more robust on $l_{\\infty}$ FGSM and PDG adversarial\nattacks and significantly outperforms the state-of-the-art against $l_2$ $C\\&W$\nattack and a wide range of well-known black-box attacks.\n"},
    {"title": "3D Augmented Reality Tangible User Interface using Commodity Hardware", "submission_date": "Mon, 2 Mar 2020 18:29:58 UTC", "authors": ["Dimitrios Chamzas", "Konstantinos Moustakas"], "pdf_link": "https://arxiv.org/pdf/2003.01092.pdf", "abstract": "<blockquote class=\"abstract mathjax\"><span class=\"descriptor\">Abstract:</span>  During the last years, the emerging field of Augmented and Virtual Reality\n(AR-VR) has seen tremendous growth. An interface that has also become very\npopular for the AR systems is the tangible interface or passive-haptic\ninterface. Specifically, an interface where users can manipulate digital\ninformation with input devices that are physical objects. This work presents a\nlow cost Augmented Reality system with a tangible interface that offers\ninteraction between the real and the virtual world. The system estimates in\nreal-time the 3D position of a small colored ball (input device), it maps it to\nthe 3D virtual world and then uses it to control the AR application that runs\nin a mobile device. Using the 3D position of our \"input\" device, it allows us\nto implement more complicated interactivity compared to a 2D input device.\nFinally, we present a simple, fast and robust algorithm that can estimate the\ncorners of a convex quadrangle. The proposed algorithm is suitable for the fast\nregistration of markers and significantly improves performance compared to the\nstate of the art.\n</blockquote>", "abstract_text": "  During the last years, the emerging field of Augmented and Virtual Reality\n(AR-VR) has seen tremendous growth. An interface that has also become very\npopular for the AR systems is the tangible interface or passive-haptic\ninterface. Specifically, an interface where users can manipulate digital\ninformation with input devices that are physical objects. This work presents a\nlow cost Augmented Reality system with a tangible interface that offers\ninteraction between the real and the virtual world. The system estimates in\nreal-time the 3D position of a small colored ball (input device), it maps it to\nthe 3D virtual world and then uses it to control the AR application that runs\nin a mobile device. Using the 3D position of our \"input\" device, it allows us\nto implement more complicated interactivity compared to a 2D input device.\nFinally, we present a simple, fast and robust algorithm that can estimate the\ncorners of a convex quadrangle. The proposed algorithm is suitable for the fast\nregistration of markers and significantly improves performance compared to the\nstate of the art.\n"},
    {"title": "V2I Connectivity-Based Dynamic Queue-Jumper Lane for Emergency Vehicles: An Approximate Dynamic Programming Approach", "submission_date": "Mon, 2 Mar 2020 16:59:21 UTC", "authors": ["Haoran Su", "Joseph Y.J. Chow", "Li Jin"], "pdf_link": "https://arxiv.org/pdf/2003.01025.pdf", "abstract": "<blockquote class=\"abstract mathjax\"><span class=\"descriptor\">Abstract:</span>  Emergency vehicle (EV) service is a key function of cities and is exceedingly\nchallenging due to urban traffic congestion. A key contributor to EV service\ndelay is the lack of communication and cooperation between vehicles blocking\nEVs. In this paper, we study the improvement of EV service using\nvehicle-to-vehicle connectivity. We consider the establishment of dynamic queue\njumper lanes (DQJLs) based on real-time coordination of connected vehicles. We\ndevelop a novel stochastic dynamic programming formulation for the DQJL\nproblem, which explicitly account for the uncertainty of drivers' reaction to\napproaching EVs. We propose a deep neural network-based approximate dynamic\nprogramming (ADP) algorithm that efficiently computes the optimal coordination\ninstructions. We also validate our approach on a micro-simulation testbed using\nSimulation On Urban Mobility (SUMO).\n</blockquote>", "abstract_text": "  Emergency vehicle (EV) service is a key function of cities and is exceedingly\nchallenging due to urban traffic congestion. A key contributor to EV service\ndelay is the lack of communication and cooperation between vehicles blocking\nEVs. In this paper, we study the improvement of EV service using\nvehicle-to-vehicle connectivity. We consider the establishment of dynamic queue\njumper lanes (DQJLs) based on real-time coordination of connected vehicles. We\ndevelop a novel stochastic dynamic programming formulation for the DQJL\nproblem, which explicitly account for the uncertainty of drivers' reaction to\napproaching EVs. We propose a deep neural network-based approximate dynamic\nprogramming (ADP) algorithm that efficiently computes the optimal coordination\ninstructions. We also validate our approach on a micro-simulation testbed using\nSimulation On Urban Mobility (SUMO).\n"},
    {"title": "Characterizing the Predictive Accuracy of Dynamic Mode Decomposition for Data-Driven Control", "submission_date": "Mon, 2 Mar 2020 17:01:11 UTC", "authors": ["Lu Qiugang", "Sungho Shin", "Victor M. Zavala"], "pdf_link": "https://arxiv.org/pdf/2003.01028.pdf", "abstract": "<blockquote class=\"abstract mathjax\"><span class=\"descriptor\">Abstract:</span>  Dynamic mode decomposition (DMD) is a versatile approach that enables the\nconstruction of low-order models from data. Controller design tasks based on\nsuch models require estimates and guarantees on predictive accuracy. In this\nwork, we provide a theoretical analysis of DMD model errors that reveals impact\nof model order and data availability. The analysis also establishes conditions\nunder which DMD models can be made asymptotically exact. We verify our results\nusing a 2D diffusion system.\n</blockquote>", "abstract_text": "  Dynamic mode decomposition (DMD) is a versatile approach that enables the\nconstruction of low-order models from data. Controller design tasks based on\nsuch models require estimates and guarantees on predictive accuracy. In this\nwork, we provide a theoretical analysis of DMD model errors that reveals impact\nof model order and data availability. The analysis also establishes conditions\nunder which DMD models can be made asymptotically exact. We verify our results\nusing a 2D diffusion system.\n"},
    {"title": "Exploring Backdoor Poisoning Attacks Against Malware Classifiers", "submission_date": "Mon, 2 Mar 2020 17:04:38 UTC", "authors": ["Giorgio Severi", "Jim Meyer", "Scott Coull", "Alina Oprea"], "pdf_link": "https://arxiv.org/pdf/2003.01031.pdf", "abstract": "<blockquote class=\"abstract mathjax\"><span class=\"descriptor\">Abstract:</span>  Current training pipelines for machine learning (ML) based malware\nclassification rely on crowdsourced threat feeds, exposing a natural attack\ninjection point. We study for the first time the susceptibility of ML malware\nclassifiers to backdoor poisoning attacks, specifically focusing on challenging\n\"clean label\" attacks where attackers do not control the sample labeling\nprocess. We propose the use of techniques from explainable machine learning to\nguide the selection of relevant features and their values to create a watermark\nin a model-agnostic fashion. Using a dataset of 800,000 Windows binaries, we\ndemonstrate effective attacks against gradient boosting decision trees and a\nneural network model for malware classification under various constraints\nimposed on the attacker. For example, an attacker injecting just 1% poison\nsamples in the training process can achieve a success rate greater than 97% by\ncrafting a watermark of 8 features out of more than 2,300 available features.\nTo demonstrate the feasibility of our backdoor attacks in practice, we create a\nwatermarking utility for Windows PE files that preserves the binary's\nfunctionality. Finally, we experiment with potential defensive strategies and\nshow the difficulties of completely defending against these powerful attacks,\nespecially when the attacks blend in with the legitimate sample distribution.\n</blockquote>", "abstract_text": "  Current training pipelines for machine learning (ML) based malware\nclassification rely on crowdsourced threat feeds, exposing a natural attack\ninjection point. We study for the first time the susceptibility of ML malware\nclassifiers to backdoor poisoning attacks, specifically focusing on challenging\n\"clean label\" attacks where attackers do not control the sample labeling\nprocess. We propose the use of techniques from explainable machine learning to\nguide the selection of relevant features and their values to create a watermark\nin a model-agnostic fashion. Using a dataset of 800,000 Windows binaries, we\ndemonstrate effective attacks against gradient boosting decision trees and a\nneural network model for malware classification under various constraints\nimposed on the attacker. For example, an attacker injecting just 1% poison\nsamples in the training process can achieve a success rate greater than 97% by\ncrafting a watermark of 8 features out of more than 2,300 available features.\nTo demonstrate the feasibility of our backdoor attacks in practice, we create a\nwatermarking utility for Windows PE files that preserves the binary's\nfunctionality. Finally, we experiment with potential defensive strategies and\nshow the difficulties of completely defending against these powerful attacks,\nespecially when the attacks blend in with the legitimate sample distribution.\n"},
    {"title": "On robot compliance. A cerebellar control approach", "submission_date": "Mon, 2 Mar 2020 17:06:19 UTC", "authors": ["Ignacio Abadia", "Francisco Naveros", "Jesus A. Garrido", "Eduardo Ros", "Niceto R. Luque"], "pdf_link": "https://arxiv.org/pdf/2003.01033.pdf", "abstract": "<blockquote class=\"abstract mathjax\"><span class=\"descriptor\">Abstract:</span>  The work presented here is a novel biological approach for the compliant\ncontrol of a robotic arm in real time (RT). We integrate a spiking cerebellar\nnetwork at the core of a feedback control loop performing torque-driven\ncontrol. The spiking cerebellar controller provides torque commands allowing\nfor accurate and coordinated arm movements. To compute these output motor\ncommands, the spiking cerebellar controller receives the robot's sensorial\nsignals, the robot's goal behavior, and an instructive signal. These input\nsignals are translated into a set of evolving spiking patterns representing\nunivocally a specific system state at every point of time.\nSpike-timing-dependent plasticity (STDP) is then supported, allowing for\nbuilding adaptive control. The spiking cerebellar controller continuously\nadapts the torque commands provided to the robot from experience as STDP is\ndeployed. Adaptive torque commands, in turn, help the spiking cerebellar\ncontroller to cope with built-in elastic elements within the robot's actuators\nmimicking human muscles (inherently elastic). We propose a natural integration\nof a bio inspired control scheme, based on the cerebellum, with a compliant\nrobot. We prove that our compliant approach outperforms the accuracy of the\ndefault factory-installed position control in a set of tasks used for\naddressing cerebellar motor behavior: controlling six degrees of freedom (DoF)\nin smooth movements, fast ballistic movements, and unstructured scenario\ncompliant movements.\n</blockquote>", "abstract_text": "  The work presented here is a novel biological approach for the compliant\ncontrol of a robotic arm in real time (RT). We integrate a spiking cerebellar\nnetwork at the core of a feedback control loop performing torque-driven\ncontrol. The spiking cerebellar controller provides torque commands allowing\nfor accurate and coordinated arm movements. To compute these output motor\ncommands, the spiking cerebellar controller receives the robot's sensorial\nsignals, the robot's goal behavior, and an instructive signal. These input\nsignals are translated into a set of evolving spiking patterns representing\nunivocally a specific system state at every point of time.\nSpike-timing-dependent plasticity (STDP) is then supported, allowing for\nbuilding adaptive control. The spiking cerebellar controller continuously\nadapts the torque commands provided to the robot from experience as STDP is\ndeployed. Adaptive torque commands, in turn, help the spiking cerebellar\ncontroller to cope with built-in elastic elements within the robot's actuators\nmimicking human muscles (inherently elastic). We propose a natural integration\nof a bio inspired control scheme, based on the cerebellum, with a compliant\nrobot. We prove that our compliant approach outperforms the accuracy of the\ndefault factory-installed position control in a set of tasks used for\naddressing cerebellar motor behavior: controlling six degrees of freedom (DoF)\nin smooth movements, fast ballistic movements, and unstructured scenario\ncompliant movements.\n"},
    {"title": "ProxEmo: Gait-based Emotion Learning and Multi-view Proxemic Fusion for Socially-Aware Robot Navigation", "submission_date": "Mon, 2 Mar 2020 17:47:49 UTC", "authors": ["Venkatraman Narayanan", "Bala Murali Manoghar", "Vishnu Sashank Dorbala", "Dinesh Manocha", "Aniket Bera"], "pdf_link": "https://arxiv.org/pdf/2003.01062.pdf", "abstract": "<blockquote class=\"abstract mathjax\"><span class=\"descriptor\">Abstract:</span>  We present ProxEmo, a novel end-to-end emotion prediction algorithm for\nsocially aware robot navigation among pedestrians. Our approach predicts the\nperceived emotions of a pedestrian from walking gaits, which is then used for\nemotion-guided navigation taking into account social and proxemic constraints.\nTo classify emotions, we propose a multi-view skeleton graph convolution-based\nmodel that works on a commodity camera mounted onto a moving robot. Our emotion\nrecognition is integrated into a mapless navigation scheme and makes no\nassumptions about the environment of pedestrian motion. It achieves a mean\naverage emotion prediction precision of 82.47% on the Emotion-Gait benchmark\ndataset. We outperform current state-of-art algorithms for emotion recognition\nfrom 3D gaits. We highlight its benefits in terms of navigation in indoor\nscenes using a Clearpath Jackal robot.\n</blockquote>", "abstract_text": "  We present ProxEmo, a novel end-to-end emotion prediction algorithm for\nsocially aware robot navigation among pedestrians. Our approach predicts the\nperceived emotions of a pedestrian from walking gaits, which is then used for\nemotion-guided navigation taking into account social and proxemic constraints.\nTo classify emotions, we propose a multi-view skeleton graph convolution-based\nmodel that works on a commodity camera mounted onto a moving robot. Our emotion\nrecognition is integrated into a mapless navigation scheme and makes no\nassumptions about the environment of pedestrian motion. It achieves a mean\naverage emotion prediction precision of 82.47% on the Emotion-Gait benchmark\ndataset. We outperform current state-of-art algorithms for emotion recognition\nfrom 3D gaits. We highlight its benefits in terms of navigation in indoor\nscenes using a Clearpath Jackal robot.\n"},
    {"title": "D3VO: Deep Depth, Deep Pose and Deep Uncertainty for Monocular Visual Odometry", "submission_date": "Mon, 2 Mar 2020 17:47:13 UTC", "authors": ["Nan Yang", "Lukas von Stumberg", "Rui Wang", "Daniel Cremers"], "pdf_link": "https://arxiv.org/pdf/2003.01060.pdf", "abstract": "<blockquote class=\"abstract mathjax\"><span class=\"descriptor\">Abstract:</span>  We propose D3VO as a novel framework for monocular visual odometry that\nexploits deep networks on three levels -- deep depth, pose and uncertainty\nestimation. We first propose a novel self-supervised monocular depth estimation\nnetwork trained on stereo videos without any external supervision. In\nparticular, it aligns the training image pairs into similar lighting condition\nwith predictive brightness transformation parameters. Besides, we model the\nphotometric uncertainties of pixels on the input images, which improves the\ndepth estimation accuracy and provides a learned weighting function for the\nphotometric residuals in direct (feature-less) visual odometry. Evaluation\nresults show that the proposed network outperforms state-of-the-art\nself-supervised depth estimation networks. D3VO tightly incorporates the\npredicted depth, pose and uncertainty into a direct visual odometry method to\nboost both the front-end tracking as well as the back-end non-linear\noptimization. We evaluate D3VO in terms of monocular visual odometry on both\nthe KITTI odometry benchmark and the EuRoC MAV dataset. The results show that\nD3VO outperforms state-of-the-art traditional monocular VO methods by a large\nmargin. It also achieves comparable results to state-of-the-art stereo/LiDAR\nodometry on KITTI and to the state-of-the-art visual-inertial odometry on EuRoC\nMAV, while using only a single camera.\n</blockquote>", "abstract_text": "  We propose D3VO as a novel framework for monocular visual odometry that\nexploits deep networks on three levels -- deep depth, pose and uncertainty\nestimation. We first propose a novel self-supervised monocular depth estimation\nnetwork trained on stereo videos without any external supervision. In\nparticular, it aligns the training image pairs into similar lighting condition\nwith predictive brightness transformation parameters. Besides, we model the\nphotometric uncertainties of pixels on the input images, which improves the\ndepth estimation accuracy and provides a learned weighting function for the\nphotometric residuals in direct (feature-less) visual odometry. Evaluation\nresults show that the proposed network outperforms state-of-the-art\nself-supervised depth estimation networks. D3VO tightly incorporates the\npredicted depth, pose and uncertainty into a direct visual odometry method to\nboost both the front-end tracking as well as the back-end non-linear\noptimization. We evaluate D3VO in terms of monocular visual odometry on both\nthe KITTI odometry benchmark and the EuRoC MAV dataset. The results show that\nD3VO outperforms state-of-the-art traditional monocular VO methods by a large\nmargin. It also achieves comparable results to state-of-the-art stereo/LiDAR\nodometry on KITTI and to the state-of-the-art visual-inertial odometry on EuRoC\nMAV, while using only a single camera.\n"},
    {"title": "Constant delay enumeration with FPT-preprocessing for conjunctive queries of bounded submodular width", "submission_date": "Mon, 2 Mar 2020 18:09:43 UTC", "authors": ["Christoph Berkholz", "Nicole Schweikardt"], "pdf_link": "https://arxiv.org/pdf/2003.01075.pdf", "abstract": "<blockquote class=\"abstract mathjax\"><span class=\"descriptor\">Abstract:</span>  Marx (STOC~2010, J.~ACM 2013) introduced the notion of submodular width of a\nconjunctive query (CQ) and showed that for any class $\\Phi$ of Boolean CQs of\nbounded submodular width, the model-checking problem for $\\Phi$ on the class of\nall finite structures is fixed-parameter tractable (FPT). Note that for\nnon-Boolean queries, the size of the query result may be far too large to be\ncomputed entirely within FPT time. We investigate the free-connex variant of\nsubmodular width and generalise Marx's result to non-Boolean queries as\nfollows: For every class $\\Phi$ of CQs of bounded free-connex submodular width,\nwithin FPT-preprocessing time we can build a data structure that allows to\nenumerate, without repetition and with constant delay, all tuples of the query\nresult. Our proof builds upon Marx's splitting routine to decompose the query\nresult into a union of results; but we have to tackle the additional technical\ndifficulty to ensure that these can be enumerated efficiently.\n</blockquote>", "abstract_text": "  Marx (STOC~2010, J.~ACM 2013) introduced the notion of submodular width of a\nconjunctive query (CQ) and showed that for any class $\\Phi$ of Boolean CQs of\nbounded submodular width, the model-checking problem for $\\Phi$ on the class of\nall finite structures is fixed-parameter tractable (FPT). Note that for\nnon-Boolean queries, the size of the query result may be far too large to be\ncomputed entirely within FPT time. We investigate the free-connex variant of\nsubmodular width and generalise Marx's result to non-Boolean queries as\nfollows: For every class $\\Phi$ of CQs of bounded free-connex submodular width,\nwithin FPT-preprocessing time we can build a data structure that allows to\nenumerate, without repetition and with constant delay, all tuples of the query\nresult. Our proof builds upon Marx's splitting routine to decompose the query\nresult into a union of results; but we have to tackle the additional technical\ndifficulty to ensure that these can be enumerated efficiently.\n"},
    {"title": "On the Global Convergence of Training Deep Linear ResNets", "submission_date": "Mon, 2 Mar 2020 18:34:49 UTC", "authors": ["Difan Zou", "Philip M. Long", "Quanquan Gu"], "pdf_link": "https://arxiv.org/pdf/2003.01094.pdf", "abstract": "<blockquote class=\"abstract mathjax\"><span class=\"descriptor\">Abstract:</span>  We study the convergence of gradient descent (GD) and stochastic gradient\ndescent (SGD) for training $L$-hidden-layer linear residual networks (ResNets).\nWe prove that for training deep residual networks with certain linear\ntransformations at input and output layers, which are fixed throughout\ntraining, both GD and SGD with zero initialization on all hidden weights can\nconverge to the global minimum of the training loss. Moreover, when\nspecializing to appropriate Gaussian random linear transformations, GD and SGD\nprovably optimize wide enough deep linear ResNets. Compared with the global\nconvergence result of GD for training standard deep linear networks (Du &amp; Hu\n2019), our condition on the neural network width is sharper by a factor of\n$O(\\kappa L)$, where $\\kappa$ denotes the condition number of the covariance\nmatrix of the training data. We further propose a modified identity input and\noutput transformations, and show that a $(d+k)$-wide neural network is\nsufficient to guarantee the global convergence of GD/SGD, where $d,k$ are the\ninput and output dimensions respectively.\n</blockquote>", "abstract_text": "  We study the convergence of gradient descent (GD) and stochastic gradient\ndescent (SGD) for training $L$-hidden-layer linear residual networks (ResNets).\nWe prove that for training deep residual networks with certain linear\ntransformations at input and output layers, which are fixed throughout\ntraining, both GD and SGD with zero initialization on all hidden weights can\nconverge to the global minimum of the training loss. Moreover, when\nspecializing to appropriate Gaussian random linear transformations, GD and SGD\nprovably optimize wide enough deep linear ResNets. Compared with the global\nconvergence result of GD for training standard deep linear networks (Du & Hu\n2019), our condition on the neural network width is sharper by a factor of\n$O(\\kappa L)$, where $\\kappa$ denotes the condition number of the covariance\nmatrix of the training data. We further propose a modified identity input and\noutput transformations, and show that a $(d+k)$-wide neural network is\nsufficient to guarantee the global convergence of GD/SGD, where $d,k$ are the\ninput and output dimensions respectively.\n"},
    {"title": "A Feature-aware SPH for Isotropic Unstructured Mesh Generation", "submission_date": "Thu, 27 Feb 2020 13:35:07 UTC", "authors": ["Zhe Ji", "Lin Fu", "Xiangyu Hu", "Nikolaus Adams"], "pdf_link": "https://arxiv.org/pdf/2003.01061.pdf", "abstract": "<blockquote class=\"abstract mathjax\"><span class=\"descriptor\">Abstract:</span>  In this paper, we present a feature-aware SPH method for the concurrent and\nautomated isotropic unstructured mesh generation. Two additional objectives are\nachieved with the proposed method compared to the original SPH-based mesh\ngenerator (Fu et al., 2019). First, a feature boundary correction term is\nintroduced to address the issue of incomplete kernel support at the boundary\nvicinity. The mesh generation of feature curves, feature surfaces and volumes\ncan be handled concurrently without explicitly following a dimensional\nsequence. Second, a two-phase model is proposed to characterize the\nmesh-generation procedure by a feature-size-adaptation phase and a\nmesh-quality-optimization phase. By proposing a new error measurement criterion\nand an adaptive control system with two sets of simulation parameters, the\nobjectives of faster feature-size adaptation and local mesh-quality improvement\nare merged into a consistent framework. The proposed method is validated with a\nset of 2D and 3D numerical tests with different complexities and scales. The\nresults demonstrate that high-quality meshes are generated with a significant\nspeedup of convergence.\n</blockquote>", "abstract_text": "  In this paper, we present a feature-aware SPH method for the concurrent and\nautomated isotropic unstructured mesh generation. Two additional objectives are\nachieved with the proposed method compared to the original SPH-based mesh\ngenerator (Fu et al., 2019). First, a feature boundary correction term is\nintroduced to address the issue of incomplete kernel support at the boundary\nvicinity. The mesh generation of feature curves, feature surfaces and volumes\ncan be handled concurrently without explicitly following a dimensional\nsequence. Second, a two-phase model is proposed to characterize the\nmesh-generation procedure by a feature-size-adaptation phase and a\nmesh-quality-optimization phase. By proposing a new error measurement criterion\nand an adaptive control system with two sets of simulation parameters, the\nobjectives of faster feature-size adaptation and local mesh-quality improvement\nare merged into a consistent framework. The proposed method is validated with a\nset of 2D and 3D numerical tests with different complexities and scales. The\nresults demonstrate that high-quality meshes are generated with a significant\nspeedup of convergence.\n"},
    {"title": "Gaussian Process Policy Optimization", "submission_date": "Mon, 2 Mar 2020 18:06:27 UTC", "authors": ["Ashish Rao", "Bidipta Sarkar", "Tejas Narayanan"], "pdf_link": "https://arxiv.org/pdf/2003.01074.pdf", "abstract": "<blockquote class=\"abstract mathjax\"><span class=\"descriptor\">Abstract:</span>  We propose a novel actor-critic, model-free reinforcement learning algorithm\nwhich employs a Bayesian method of parameter space exploration to solve\nenvironments. A Gaussian process is used to learn the expected return of a\npolicy given the policy's parameters. The system is trained by updating the\nparameters using gradient descent on a new surrogate loss function consisting\nof the Proximal Policy Optimization 'Clipped' loss function and a bonus term\nrepresenting the expected improvement acquisition function given by the\nGaussian process. This new method is shown to be comparable to and at times\nempirically outperform current algorithms on environments that simulate robotic\nlocomotion using the MuJoCo physics engine.\n</blockquote>", "abstract_text": "  We propose a novel actor-critic, model-free reinforcement learning algorithm\nwhich employs a Bayesian method of parameter space exploration to solve\nenvironments. A Gaussian process is used to learn the expected return of a\npolicy given the policy's parameters. The system is trained by updating the\nparameters using gradient descent on a new surrogate loss function consisting\nof the Proximal Policy Optimization 'Clipped' loss function and a bonus term\nrepresenting the expected improvement acquisition function given by the\nGaussian process. This new method is shown to be comparable to and at times\nempirically outperform current algorithms on environments that simulate robotic\nlocomotion using the MuJoCo physics engine.\n"},
    {"title": "Bridging the Gap Between Theory and Practice on Insertion-Intensive Database", "submission_date": "Mon, 2 Mar 2020 17:50:07 UTC", "authors": ["Sepanta Zeighami", "Raymond Chi-Wing Wong"], "pdf_link": "https://arxiv.org/pdf/2003.01064.pdf", "abstract": "<blockquote class=\"abstract mathjax\"><span class=\"descriptor\">Abstract:</span>  With the prevalence of online platforms, today, data is being generated and\naccessed by users at a very high rate. Besides, applications such as stock\ntrading or high frequency trading require guaranteed low delays for performing\nan operation on a database. It is consequential to design databases that\nguarantee data insertion and query at a consistently high rate without\nintroducing any long delay during insertion. In this paper, we propose Nested\nB-trees (NB-trees), an index that can achieve a consistently high insertion\nrate on large volumes of data, while providing asymptotically optimal query\nperformance that is very efficient in practice. Nested B-trees support\ninsertions at rates higher than LSM-trees, the state-of-the-art index for\ninsertion-intensive workloads, while avoiding their long insertion delays and\nimproving on their query performance. They approach the query performance of\nB-trees when complemented with Bloom filters. In our experiments, NB-trees had\nworst-case delays up to 1000 smaller than LevelDB, RocksDB and bLSM, commonly\nused LSM-tree data-stores, could perform queries more than 4 times faster than\nLevelDB and 1.5 times faster than bLSM and RocksDB, while also outperforming\nthem in terms of average insertion rate.\n</blockquote>", "abstract_text": "  With the prevalence of online platforms, today, data is being generated and\naccessed by users at a very high rate. Besides, applications such as stock\ntrading or high frequency trading require guaranteed low delays for performing\nan operation on a database. It is consequential to design databases that\nguarantee data insertion and query at a consistently high rate without\nintroducing any long delay during insertion. In this paper, we propose Nested\nB-trees (NB-trees), an index that can achieve a consistently high insertion\nrate on large volumes of data, while providing asymptotically optimal query\nperformance that is very efficient in practice. Nested B-trees support\ninsertions at rates higher than LSM-trees, the state-of-the-art index for\ninsertion-intensive workloads, while avoiding their long insertion delays and\nimproving on their query performance. They approach the query performance of\nB-trees when complemented with Bloom filters. In our experiments, NB-trees had\nworst-case delays up to 1000 smaller than LevelDB, RocksDB and bLSM, commonly\nused LSM-tree data-stores, could perform queries more than 4 times faster than\nLevelDB and 1.5 times faster than bLSM and RocksDB, while also outperforming\nthem in terms of average insertion rate.\n"},
    {"title": "Learning from Positive and Unlabeled Data by Identifying the Annotation Process", "submission_date": "Mon, 2 Mar 2020 17:57:12 UTC", "authors": ["Naji Shajarisales", "Peter Spirtes", "Kun Zhang"], "pdf_link": "https://arxiv.org/pdf/2003.01067.pdf", "abstract": "<blockquote class=\"abstract mathjax\"><span class=\"descriptor\">Abstract:</span>  In binary classification, Learning from Positive and Unlabeled data (LePU) is\nsemi-supervised learning but with labeled elements from only one class. Most of\nthe research on LePU relies on some form of independence between the selection\nprocess of annotated examples and the features of the annotated class, known as\nthe Selected Completely At Random (SCAR) assumption. Yet the annotation process\nis an important part of the data collection, and in many cases it naturally\ndepends on certain features of the data (e.g., the intensity of an image and\nthe size of the object to be detected in the image). Without any constraints on\nthe model for the annotation process, classification results in the LePU\nproblem will be highly non-unique. So proper, flexible constraints are needed.\nIn this work we incorporate more flexible and realistic models for the\nannotation process than SCAR, and more importantly, offer a solution for the\nchallenging LePU problem. On the theory side, we establish the identifiability\nof the properties of the annotation process and the classification function, in\nlight of the considered constraints on the data-generating process. We also\npropose an inference algorithm to learn the parameters of the model, with\nsuccessful experimental results on both simulated and real data. We also\npropose a novel real-world dataset forLePU, as a benchmark dataset for future\nstudies.\n</blockquote>", "abstract_text": "  In binary classification, Learning from Positive and Unlabeled data (LePU) is\nsemi-supervised learning but with labeled elements from only one class. Most of\nthe research on LePU relies on some form of independence between the selection\nprocess of annotated examples and the features of the annotated class, known as\nthe Selected Completely At Random (SCAR) assumption. Yet the annotation process\nis an important part of the data collection, and in many cases it naturally\ndepends on certain features of the data (e.g., the intensity of an image and\nthe size of the object to be detected in the image). Without any constraints on\nthe model for the annotation process, classification results in the LePU\nproblem will be highly non-unique. So proper, flexible constraints are needed.\nIn this work we incorporate more flexible and realistic models for the\nannotation process than SCAR, and more importantly, offer a solution for the\nchallenging LePU problem. On the theory side, we establish the identifiability\nof the properties of the annotation process and the classification function, in\nlight of the considered constraints on the data-generating process. We also\npropose an inference algorithm to learn the parameters of the model, with\nsuccessful experimental results on both simulated and real data. We also\npropose a novel real-world dataset forLePU, as a benchmark dataset for future\nstudies.\n"},
    {"title": "On-the-fly Optimization of Parallel Computation of Symbolic Symplectic Invariants", "submission_date": "Mon, 2 Mar 2020 18:14:17 UTC", "authors": ["Joseph Ben Geloun", "Camille Coti", "Allen D. Malony"], "pdf_link": "https://arxiv.org/pdf/2003.01081.pdf", "abstract": "<blockquote class=\"abstract mathjax\"><span class=\"descriptor\">Abstract:</span>  Group invariants are used in high energy physics to define quantum field\ntheory interactions. In this paper, we are presenting the parallel algebraic\ncomputation of special invariants called symplectic and even focusing on one\nparticular invariant that finds recent interest in physics. Our results will\nexport to other invariants. The cost of performing basic computations on the\nmultivariate polynomials involved evolves during the computation, as the\npolynomials get larger or with an increasing number of terms. However, in some\ncases, they stay small. Traditionally, high-performance software is optimized\nby running it on a smaller data set in order to use profiling information to\nset some tuning parameters. Since the (communication and computation) costs\nevolve during the computation, the first iterations of the computation might\nnot be representative of the rest of the computation and this approach cannot\nbe applied in this case. To cope with this evolution, we are presenting an\napproach to get performance data and tune the algorithm during the execution.\n</blockquote>", "abstract_text": "  Group invariants are used in high energy physics to define quantum field\ntheory interactions. In this paper, we are presenting the parallel algebraic\ncomputation of special invariants called symplectic and even focusing on one\nparticular invariant that finds recent interest in physics. Our results will\nexport to other invariants. The cost of performing basic computations on the\nmultivariate polynomials involved evolves during the computation, as the\npolynomials get larger or with an increasing number of terms. However, in some\ncases, they stay small. Traditionally, high-performance software is optimized\nby running it on a smaller data set in order to use profiling information to\nset some tuning parameters. Since the (communication and computation) costs\nevolve during the computation, the first iterations of the computation might\nnot be representative of the rest of the computation and this approach cannot\nbe applied in this case. To cope with this evolution, we are presenting an\napproach to get performance data and tune the algorithm during the execution.\n"},
    {"title": "Distributed Leader-Follower Formation Tracking Control of Multiple Quad-rotors", "submission_date": "Mon, 2 Mar 2020 18:18:54 UTC", "authors": ["Lixia Yan", "Baoli Ma"], "pdf_link": "https://arxiv.org/pdf/2003.01084.pdf", "abstract": "<blockquote class=\"abstract mathjax\"><span class=\"descriptor\">Abstract:</span>  The leader-follower formation control analysis for multiple quad-rotor\nsystems is investigated in this paper. To achieve predefined formation in the\nthree-dimensional air space ($x,y$ and $z$), a novel local tracking control law\nand a distributed observer are obtained. The local tracking control law starts\nwith finding a bounded continuous yet greater-than-zero control in $z$, based\non which following a feedback linearization controls derived for errors\nassociated with $x$ and $y$. The distributed observer achieves position\ncoordination among followers, though there are only partial followers can know\nthe leader's states and only neighboring communication is available. Simulation\nresults validate the proposed formation scheme.\n</blockquote>", "abstract_text": "  The leader-follower formation control analysis for multiple quad-rotor\nsystems is investigated in this paper. To achieve predefined formation in the\nthree-dimensional air space ($x,y$ and $z$), a novel local tracking control law\nand a distributed observer are obtained. The local tracking control law starts\nwith finding a bounded continuous yet greater-than-zero control in $z$, based\non which following a feedback linearization controls derived for errors\nassociated with $x$ and $y$. The distributed observer achieves position\ncoordination among followers, though there are only partial followers can know\nthe leader's states and only neighboring communication is available. Simulation\nresults validate the proposed formation scheme.\n"},
    {"title": "Controller Tuning for Active Queue Management Using a Parameter Space Method", "submission_date": "Mon, 2 Mar 2020 18:09:47 UTC", "authors": ["Murat Saglam", "Sami Ezercan", "Suat Gumussoy", "Hitay Ozbay"], "pdf_link": "https://arxiv.org/pdf/2003.01076.pdf", "abstract": "<blockquote class=\"abstract mathjax\"><span class=\"descriptor\">Abstract:</span>  In recent years, different mathematical models have been proposed for widely\nused internet control mechanisms. Simple low order controllers (such as PID,\nand Smith predictor based linear controllers that are easy to implement) are\ndesired for network traffic management. In order to design such simple\ncontrollers for Active Queue Management (AQM), delay based linear models have\nbeen considered. In this paper we discuss tuning of the PID controllers by\nusing a parameter space method, which computes stability regions of a class of\nquasi-polynomials in terms of free controller parameters.\n</blockquote>", "abstract_text": "  In recent years, different mathematical models have been proposed for widely\nused internet control mechanisms. Simple low order controllers (such as PID,\nand Smith predictor based linear controllers that are easy to implement) are\ndesired for network traffic management. In order to design such simple\ncontrollers for Active Queue Management (AQM), delay based linear models have\nbeen considered. In this paper we discuss tuning of the PID controllers by\nusing a parameter space method, which computes stability regions of a class of\nquasi-polynomials in terms of free controller parameters.\n"},
    {"title": "3D Augmented Reality Tangible User Interface using Commodity Hardware", "submission_date": "Mon, 2 Mar 2020 18:29:58 UTC", "authors": ["Dimitrios Chamzas", "Konstantinos Moustakas"], "pdf_link": "https://arxiv.org/pdf/2003.01092.pdf", "abstract": "<blockquote class=\"abstract mathjax\"><span class=\"descriptor\">Abstract:</span>  During the last years, the emerging field of Augmented and Virtual Reality\n(AR-VR) has seen tremendous growth. An interface that has also become very\npopular for the AR systems is the tangible interface or passive-haptic\ninterface. Specifically, an interface where users can manipulate digital\ninformation with input devices that are physical objects. This work presents a\nlow cost Augmented Reality system with a tangible interface that offers\ninteraction between the real and the virtual world. The system estimates in\nreal-time the 3D position of a small colored ball (input device), it maps it to\nthe 3D virtual world and then uses it to control the AR application that runs\nin a mobile device. Using the 3D position of our \"input\" device, it allows us\nto implement more complicated interactivity compared to a 2D input device.\nFinally, we present a simple, fast and robust algorithm that can estimate the\ncorners of a convex quadrangle. The proposed algorithm is suitable for the fast\nregistration of markers and significantly improves performance compared to the\nstate of the art.\n</blockquote>", "abstract_text": "  During the last years, the emerging field of Augmented and Virtual Reality\n(AR-VR) has seen tremendous growth. An interface that has also become very\npopular for the AR systems is the tangible interface or passive-haptic\ninterface. Specifically, an interface where users can manipulate digital\ninformation with input devices that are physical objects. This work presents a\nlow cost Augmented Reality system with a tangible interface that offers\ninteraction between the real and the virtual world. The system estimates in\nreal-time the 3D position of a small colored ball (input device), it maps it to\nthe 3D virtual world and then uses it to control the AR application that runs\nin a mobile device. Using the 3D position of our \"input\" device, it allows us\nto implement more complicated interactivity compared to a 2D input device.\nFinally, we present a simple, fast and robust algorithm that can estimate the\ncorners of a convex quadrangle. The proposed algorithm is suitable for the fast\nregistration of markers and significantly improves performance compared to the\nstate of the art.\n"},
    {"title": "Predictive Coding for Locally-Linear Control", "submission_date": "Mon, 2 Mar 2020 18:20:41 UTC", "authors": ["Rui Shu", "Tung Nguyen", "Yinlam Chow", "Tuan Pham", "Khoat Than", "Mohammad Ghavamzadeh", "Stefano Ermon", "Hung H. Bui"], "pdf_link": "https://arxiv.org/pdf/2003.01086.pdf", "abstract": "<blockquote class=\"abstract mathjax\"><span class=\"descriptor\">Abstract:</span>  High-dimensional observations and unknown dynamics are major challenges when\napplying optimal control to many real-world decision making tasks. The Learning\nControllable Embedding (LCE) framework addresses these challenges by embedding\nthe observations into a lower dimensional latent space, estimating the latent\ndynamics, and then performing control directly in the latent space. To ensure\nthe learned latent dynamics are predictive of next-observations, all existing\nLCE approaches decode back into the observation space and explicitly perform\nnext-observation prediction---a challenging high-dimensional task that\nfurthermore introduces a large number of nuisance parameters (i.e., the\ndecoder) which are discarded during control. In this paper, we propose a novel\ninformation-theoretic LCE approach and show theoretically that explicit\nnext-observation prediction can be replaced with predictive coding. We then use\npredictive coding to develop a decoder-free LCE model whose latent dynamics are\namenable to locally-linear control. Extensive experiments on benchmark tasks\nshow that our model reliably learns a controllable latent space that leads to\nsuperior performance when compared with state-of-the-art LCE baselines.\n</blockquote>", "abstract_text": "  High-dimensional observations and unknown dynamics are major challenges when\napplying optimal control to many real-world decision making tasks. The Learning\nControllable Embedding (LCE) framework addresses these challenges by embedding\nthe observations into a lower dimensional latent space, estimating the latent\ndynamics, and then performing control directly in the latent space. To ensure\nthe learned latent dynamics are predictive of next-observations, all existing\nLCE approaches decode back into the observation space and explicitly perform\nnext-observation prediction---a challenging high-dimensional task that\nfurthermore introduces a large number of nuisance parameters (i.e., the\ndecoder) which are discarded during control. In this paper, we propose a novel\ninformation-theoretic LCE approach and show theoretically that explicit\nnext-observation prediction can be replaced with predictive coding. We then use\npredictive coding to develop a decoder-free LCE model whose latent dynamics are\namenable to locally-linear control. Extensive experiments on benchmark tasks\nshow that our model reliably learns a controllable latent space that leads to\nsuperior performance when compared with state-of-the-art LCE baselines.\n"},
    {"title": "Learn2Perturb: an End-to-end Feature Perturbation Learning to Improve Adversarial Robustness", "submission_date": "Mon, 2 Mar 2020 18:27:35 UTC", "authors": ["Ahmadreza Jeddi", "Mohammad Javad Shafiee", "Michelle Karg", "Christian Scharfenberger", "Alexander Wong"], "pdf_link": "https://arxiv.org/pdf/2003.01090.pdf", "abstract": "<blockquote class=\"abstract mathjax\"><span class=\"descriptor\">Abstract:</span>  While deep neural networks have been achieving state-of-the-art performance\nacross a wide variety of applications, their vulnerability to adversarial\nattacks limits their widespread deployment for safety-critical applications.\nAlongside other adversarial defense approaches being investigated, there has\nbeen a very recent interest in improving adversarial robustness in deep neural\nnetworks through the introduction of perturbations during the training process.\nHowever, such methods leverage fixed, pre-defined perturbations and require\nsignificant hyper-parameter tuning that makes them very difficult to leverage\nin a general fashion. In this study, we introduce Learn2Perturb, an end-to-end\nfeature perturbation learning approach for improving the adversarial robustness\nof deep neural networks. More specifically, we introduce novel\nperturbation-injection modules that are incorporated at each layer to perturb\nthe feature space and increase uncertainty in the network. This feature\nperturbation is performed at both the training and the inference stages.\nFurthermore, inspired by the Expectation-Maximization, an alternating\nback-propagation training algorithm is introduced to train the network and\nnoise parameters consecutively. Experimental results on CIFAR-10 and CIFAR-100\ndatasets show that the proposed Learn2Perturb method can result in deep neural\nnetworks which are $4-7\\%$ more robust on $l_{\\infty}$ FGSM and PDG adversarial\nattacks and significantly outperforms the state-of-the-art against $l_2$ $C\\&amp;W$\nattack and a wide range of well-known black-box attacks.\n</blockquote>", "abstract_text": "  While deep neural networks have been achieving state-of-the-art performance\nacross a wide variety of applications, their vulnerability to adversarial\nattacks limits their widespread deployment for safety-critical applications.\nAlongside other adversarial defense approaches being investigated, there has\nbeen a very recent interest in improving adversarial robustness in deep neural\nnetworks through the introduction of perturbations during the training process.\nHowever, such methods leverage fixed, pre-defined perturbations and require\nsignificant hyper-parameter tuning that makes them very difficult to leverage\nin a general fashion. In this study, we introduce Learn2Perturb, an end-to-end\nfeature perturbation learning approach for improving the adversarial robustness\nof deep neural networks. More specifically, we introduce novel\nperturbation-injection modules that are incorporated at each layer to perturb\nthe feature space and increase uncertainty in the network. This feature\nperturbation is performed at both the training and the inference stages.\nFurthermore, inspired by the Expectation-Maximization, an alternating\nback-propagation training algorithm is introduced to train the network and\nnoise parameters consecutively. Experimental results on CIFAR-10 and CIFAR-100\ndatasets show that the proposed Learn2Perturb method can result in deep neural\nnetworks which are $4-7\\%$ more robust on $l_{\\infty}$ FGSM and PDG adversarial\nattacks and significantly outperforms the state-of-the-art against $l_2$ $C\\&W$\nattack and a wide range of well-known black-box attacks.\n"},
    {"title": "Remarks on Strong Stabilization and Stable H-infinity Controller Design", "submission_date": "Mon, 2 Mar 2020 18:25:29 UTC", "authors": ["Suat Gumussoy", "Hitay Ozbay"], "pdf_link": "https://arxiv.org/pdf/2003.01089.pdf", "abstract": "<blockquote class=\"abstract mathjax\"><span class=\"descriptor\">Abstract:</span>  A state space based design method is given to find strongly stabilizing\ncontrollers for multi-input-multi-output plants (MIMO). A sufficient condition\nis derived for the existence of suboptimal stable H-infinity controller in\nterms of linear matrix inequalities (LMI) and the controller order is twice\nthat of the plant. A new parameterization of strongly stabilizing controllers\nis determined using linear fractional transformations (LFT).\n</blockquote>", "abstract_text": "  A state space based design method is given to find strongly stabilizing\ncontrollers for multi-input-multi-output plants (MIMO). A sufficient condition\nis derived for the existence of suboptimal stable H-infinity controller in\nterms of linear matrix inequalities (LMI) and the controller order is twice\nthat of the plant. A new parameterization of strongly stabilizing controllers\nis determined using linear fractional transformations (LFT).\n"},
    {"title": "On robot compliance. A cerebellar control approach", "submission_date": "Mon, 2 Mar 2020 17:06:19 UTC", "authors": ["Ignacio Abadia", "Francisco Naveros", "Jesus A. Garrido", "Eduardo Ros", "Niceto R. Luque"], "pdf_link": "https://arxiv.org/pdf/2003.01033.pdf", "abstract": "<blockquote class=\"abstract mathjax\"><span class=\"descriptor\">Abstract:</span>  The work presented here is a novel biological approach for the compliant\ncontrol of a robotic arm in real time (RT). We integrate a spiking cerebellar\nnetwork at the core of a feedback control loop performing torque-driven\ncontrol. The spiking cerebellar controller provides torque commands allowing\nfor accurate and coordinated arm movements. To compute these output motor\ncommands, the spiking cerebellar controller receives the robot's sensorial\nsignals, the robot's goal behavior, and an instructive signal. These input\nsignals are translated into a set of evolving spiking patterns representing\nunivocally a specific system state at every point of time.\nSpike-timing-dependent plasticity (STDP) is then supported, allowing for\nbuilding adaptive control. The spiking cerebellar controller continuously\nadapts the torque commands provided to the robot from experience as STDP is\ndeployed. Adaptive torque commands, in turn, help the spiking cerebellar\ncontroller to cope with built-in elastic elements within the robot's actuators\nmimicking human muscles (inherently elastic). We propose a natural integration\nof a bio inspired control scheme, based on the cerebellum, with a compliant\nrobot. We prove that our compliant approach outperforms the accuracy of the\ndefault factory-installed position control in a set of tasks used for\naddressing cerebellar motor behavior: controlling six degrees of freedom (DoF)\nin smooth movements, fast ballistic movements, and unstructured scenario\ncompliant movements.\n</blockquote>", "abstract_text": "  The work presented here is a novel biological approach for the compliant\ncontrol of a robotic arm in real time (RT). We integrate a spiking cerebellar\nnetwork at the core of a feedback control loop performing torque-driven\ncontrol. The spiking cerebellar controller provides torque commands allowing\nfor accurate and coordinated arm movements. To compute these output motor\ncommands, the spiking cerebellar controller receives the robot's sensorial\nsignals, the robot's goal behavior, and an instructive signal. These input\nsignals are translated into a set of evolving spiking patterns representing\nunivocally a specific system state at every point of time.\nSpike-timing-dependent plasticity (STDP) is then supported, allowing for\nbuilding adaptive control. The spiking cerebellar controller continuously\nadapts the torque commands provided to the robot from experience as STDP is\ndeployed. Adaptive torque commands, in turn, help the spiking cerebellar\ncontroller to cope with built-in elastic elements within the robot's actuators\nmimicking human muscles (inherently elastic). We propose a natural integration\nof a bio inspired control scheme, based on the cerebellum, with a compliant\nrobot. We prove that our compliant approach outperforms the accuracy of the\ndefault factory-installed position control in a set of tasks used for\naddressing cerebellar motor behavior: controlling six degrees of freedom (DoF)\nin smooth movements, fast ballistic movements, and unstructured scenario\ncompliant movements.\n"},
    {"title": "V2I Connectivity-Based Dynamic Queue-Jumper Lane for Emergency Vehicles: An Approximate Dynamic Programming Approach", "submission_date": "Mon, 2 Mar 2020 16:59:21 UTC", "authors": ["Haoran Su", "Joseph Y.J. Chow", "Li Jin"], "pdf_link": "https://arxiv.org/pdf/2003.01025.pdf", "abstract": "<blockquote class=\"abstract mathjax\"><span class=\"descriptor\">Abstract:</span>  Emergency vehicle (EV) service is a key function of cities and is exceedingly\nchallenging due to urban traffic congestion. A key contributor to EV service\ndelay is the lack of communication and cooperation between vehicles blocking\nEVs. In this paper, we study the improvement of EV service using\nvehicle-to-vehicle connectivity. We consider the establishment of dynamic queue\njumper lanes (DQJLs) based on real-time coordination of connected vehicles. We\ndevelop a novel stochastic dynamic programming formulation for the DQJL\nproblem, which explicitly account for the uncertainty of drivers' reaction to\napproaching EVs. We propose a deep neural network-based approximate dynamic\nprogramming (ADP) algorithm that efficiently computes the optimal coordination\ninstructions. We also validate our approach on a micro-simulation testbed using\nSimulation On Urban Mobility (SUMO).\n</blockquote>", "abstract_text": "  Emergency vehicle (EV) service is a key function of cities and is exceedingly\nchallenging due to urban traffic congestion. A key contributor to EV service\ndelay is the lack of communication and cooperation between vehicles blocking\nEVs. In this paper, we study the improvement of EV service using\nvehicle-to-vehicle connectivity. We consider the establishment of dynamic queue\njumper lanes (DQJLs) based on real-time coordination of connected vehicles. We\ndevelop a novel stochastic dynamic programming formulation for the DQJL\nproblem, which explicitly account for the uncertainty of drivers' reaction to\napproaching EVs. We propose a deep neural network-based approximate dynamic\nprogramming (ADP) algorithm that efficiently computes the optimal coordination\ninstructions. We also validate our approach on a micro-simulation testbed using\nSimulation On Urban Mobility (SUMO).\n"},
    {"title": "Characterizing the Predictive Accuracy of Dynamic Mode Decomposition for Data-Driven Control", "submission_date": "Mon, 2 Mar 2020 17:01:11 UTC", "authors": ["Lu Qiugang", "Sungho Shin", "Victor M. Zavala"], "pdf_link": "https://arxiv.org/pdf/2003.01028.pdf", "abstract": "<blockquote class=\"abstract mathjax\"><span class=\"descriptor\">Abstract:</span>  Dynamic mode decomposition (DMD) is a versatile approach that enables the\nconstruction of low-order models from data. Controller design tasks based on\nsuch models require estimates and guarantees on predictive accuracy. In this\nwork, we provide a theoretical analysis of DMD model errors that reveals impact\nof model order and data availability. The analysis also establishes conditions\nunder which DMD models can be made asymptotically exact. We verify our results\nusing a 2D diffusion system.\n</blockquote>", "abstract_text": "  Dynamic mode decomposition (DMD) is a versatile approach that enables the\nconstruction of low-order models from data. Controller design tasks based on\nsuch models require estimates and guarantees on predictive accuracy. In this\nwork, we provide a theoretical analysis of DMD model errors that reveals impact\nof model order and data availability. The analysis also establishes conditions\nunder which DMD models can be made asymptotically exact. We verify our results\nusing a 2D diffusion system.\n"},
    {"title": "One or Two Components? The Scattering Transform Answers", "submission_date": "Mon, 2 Mar 2020 17:15:06 UTC", "authors": ["Vincent Lostanlen", "Alice Cohen-Hadria", "Juan Pablo Bello"], "pdf_link": "https://arxiv.org/pdf/2003.01037.pdf", "abstract": "<blockquote class=\"abstract mathjax\"><span class=\"descriptor\">Abstract:</span>  With the aim of constructing a biologically plausible model of machine\nlistening, we study the representation of a multicomponent stationary signal by\na wavelet scattering network. First, we show that renormalizing second-order\nnodes by their first-order parents gives a simple numerical criterion to assess\nwhether two neighboring components will interfere psychoacoustically. Secondly,\nwe run a manifold learning algorithm (Isomap) on scattering coefficients to\nvisualize the similarity space underlying parametric additive synthesis.\nThirdly, we generalize the \"one or two components\" framework to three sine\nwaves or more, and prove that the effective scattering depth of a Fourier\nseries grows in logarithmic proportion to its bandwidth.\n</blockquote>", "abstract_text": "  With the aim of constructing a biologically plausible model of machine\nlistening, we study the representation of a multicomponent stationary signal by\na wavelet scattering network. First, we show that renormalizing second-order\nnodes by their first-order parents gives a simple numerical criterion to assess\nwhether two neighboring components will interfere psychoacoustically. Secondly,\nwe run a manifold learning algorithm (Isomap) on scattering coefficients to\nvisualize the similarity space underlying parametric additive synthesis.\nThirdly, we generalize the \"one or two components\" framework to three sine\nwaves or more, and prove that the effective scattering depth of a Fourier\nseries grows in logarithmic proportion to its bandwidth.\n"},
    {"title": "Gated Mechanism for Attention Based Multimodal Sentiment Analysis", "submission_date": "Fri, 21 Feb 2020 06:58:03 UTC", "authors": ["Ayush Kumar", "Jithendra Vepa"], "pdf_link": "https://arxiv.org/pdf/2003.01043.pdf", "abstract": "<blockquote class=\"abstract mathjax\"><span class=\"descriptor\">Abstract:</span>  Multimodal sentiment analysis has recently gained popularity because of its\nrelevance to social media posts, customer service calls and video blogs. In\nthis paper, we address three aspects of multimodal sentiment analysis; 1. Cross\nmodal interaction learning, i.e. how multiple modalities contribute to the\nsentiment, 2. Learning long-term dependencies in multimodal interactions and 3.\nFusion of unimodal and cross modal cues. Out of these three, we find that\nlearning cross modal interactions is beneficial for this problem. We perform\nexperiments on two benchmark datasets, CMU Multimodal Opinion level Sentiment\nIntensity (CMU-MOSI) and CMU Multimodal Opinion Sentiment and Emotion Intensity\n(CMU-MOSEI) corpus. Our approach on both these tasks yields accuracies of 83.9%\nand 81.1% respectively, which is 1.6% and 1.34% absolute improvement over\ncurrent state-of-the-art.\n</blockquote>", "abstract_text": "  Multimodal sentiment analysis has recently gained popularity because of its\nrelevance to social media posts, customer service calls and video blogs. In\nthis paper, we address three aspects of multimodal sentiment analysis; 1. Cross\nmodal interaction learning, i.e. how multiple modalities contribute to the\nsentiment, 2. Learning long-term dependencies in multimodal interactions and 3.\nFusion of unimodal and cross modal cues. Out of these three, we find that\nlearning cross modal interactions is beneficial for this problem. We perform\nexperiments on two benchmark datasets, CMU Multimodal Opinion level Sentiment\nIntensity (CMU-MOSI) and CMU Multimodal Opinion Sentiment and Emotion Intensity\n(CMU-MOSEI) corpus. Our approach on both these tasks yields accuracies of 83.9%\nand 81.1% respectively, which is 1.6% and 1.34% absolute improvement over\ncurrent state-of-the-art.\n"},
    {"title": "Exploring Backdoor Poisoning Attacks Against Malware Classifiers", "submission_date": "Mon, 2 Mar 2020 17:04:38 UTC", "authors": ["Giorgio Severi", "Jim Meyer", "Scott Coull", "Alina Oprea"], "pdf_link": "https://arxiv.org/pdf/2003.01031.pdf", "abstract": "<blockquote class=\"abstract mathjax\"><span class=\"descriptor\">Abstract:</span>  Current training pipelines for machine learning (ML) based malware\nclassification rely on crowdsourced threat feeds, exposing a natural attack\ninjection point. We study for the first time the susceptibility of ML malware\nclassifiers to backdoor poisoning attacks, specifically focusing on challenging\n\"clean label\" attacks where attackers do not control the sample labeling\nprocess. We propose the use of techniques from explainable machine learning to\nguide the selection of relevant features and their values to create a watermark\nin a model-agnostic fashion. Using a dataset of 800,000 Windows binaries, we\ndemonstrate effective attacks against gradient boosting decision trees and a\nneural network model for malware classification under various constraints\nimposed on the attacker. For example, an attacker injecting just 1% poison\nsamples in the training process can achieve a success rate greater than 97% by\ncrafting a watermark of 8 features out of more than 2,300 available features.\nTo demonstrate the feasibility of our backdoor attacks in practice, we create a\nwatermarking utility for Windows PE files that preserves the binary's\nfunctionality. Finally, we experiment with potential defensive strategies and\nshow the difficulties of completely defending against these powerful attacks,\nespecially when the attacks blend in with the legitimate sample distribution.\n</blockquote>", "abstract_text": "  Current training pipelines for machine learning (ML) based malware\nclassification rely on crowdsourced threat feeds, exposing a natural attack\ninjection point. We study for the first time the susceptibility of ML malware\nclassifiers to backdoor poisoning attacks, specifically focusing on challenging\n\"clean label\" attacks where attackers do not control the sample labeling\nprocess. We propose the use of techniques from explainable machine learning to\nguide the selection of relevant features and their values to create a watermark\nin a model-agnostic fashion. Using a dataset of 800,000 Windows binaries, we\ndemonstrate effective attacks against gradient boosting decision trees and a\nneural network model for malware classification under various constraints\nimposed on the attacker. For example, an attacker injecting just 1% poison\nsamples in the training process can achieve a success rate greater than 97% by\ncrafting a watermark of 8 features out of more than 2,300 available features.\nTo demonstrate the feasibility of our backdoor attacks in practice, we create a\nwatermarking utility for Windows PE files that preserves the binary's\nfunctionality. Finally, we experiment with potential defensive strategies and\nshow the difficulties of completely defending against these powerful attacks,\nespecially when the attacks blend in with the legitimate sample distribution.\n"},
    {"title": "Scaling Up Multiagent Reinforcement Learning for Robotic Systems: Learn an Adaptive Sparse Communication Graph", "submission_date": "Mon, 2 Mar 2020 17:18:25 UTC", "authors": ["Chuangchuang Sun", "Macheng Shen", "Jonathan P. How"], "pdf_link": "https://arxiv.org/pdf/2003.01040.pdf", "abstract": "<blockquote class=\"abstract mathjax\"><span class=\"descriptor\">Abstract:</span>  The complexity of multiagent reinforcement learning (MARL) in multiagent\nsystems increases exponentially with respect to the agent number. This\nscalability issue prevents MARL from being applied in large-scale multiagent\nsystems. However, one critical feature in MARL that is often neglected is that\nthe interactions between agents are quite sparse. Without exploiting this\nsparsity structure, existing works aggregate information from all of the agents\nand thus have a high sample complexity. To address this issue, we propose an\nadaptive sparse attention mechanism by generalizing a sparsity-inducing\nactivation function. Then a sparse communication graph in MARL is learned by\ngraph neural networks based on this new attention mechanism. Through this\nsparsity structure, the agents can communicate in an effective as well as\nefficient way via only selectively attending to agents that matter the most and\nthus the scale of the MARL problem is reduced with little optimality\ncompromised. Comparative results show that our algorithm can learn an\ninterpretable sparse structure and outperforms previous works by a significant\nmargin on applications involving a large-scale multiagent system.\n</blockquote>", "abstract_text": "  The complexity of multiagent reinforcement learning (MARL) in multiagent\nsystems increases exponentially with respect to the agent number. This\nscalability issue prevents MARL from being applied in large-scale multiagent\nsystems. However, one critical feature in MARL that is often neglected is that\nthe interactions between agents are quite sparse. Without exploiting this\nsparsity structure, existing works aggregate information from all of the agents\nand thus have a high sample complexity. To address this issue, we propose an\nadaptive sparse attention mechanism by generalizing a sparsity-inducing\nactivation function. Then a sparse communication graph in MARL is learned by\ngraph neural networks based on this new attention mechanism. Through this\nsparsity structure, the agents can communicate in an effective as well as\nefficient way via only selectively attending to agents that matter the most and\nthus the scale of the MARL problem is reduced with little optimality\ncompromised. Comparative results show that our algorithm can learn an\ninterpretable sparse structure and outperforms previous works by a significant\nmargin on applications involving a large-scale multiagent system.\n"},
    {"title": "Tensor Networks for Language Modeling", "submission_date": "Mon, 2 Mar 2020 17:16:05 UTC", "authors": ["Jacob Miller", "Guillaume Rabusseau", "John Terilla"], "pdf_link": "https://arxiv.org/pdf/2003.01039.pdf", "abstract": "<blockquote class=\"abstract mathjax\"><span class=\"descriptor\">Abstract:</span>  The tensor network formalism has enjoyed over two decades of success in\nmodeling the behavior of complex quantum-mechanical systems, but has only\nrecently and sporadically been leveraged in machine learning. Here we introduce\na uniform matrix product state (u-MPS) model for probabilistic modeling of\nsequence data. We identify several distinctive features of this recurrent\ngenerative model, notably the ability to condition or marginalize sampling on\ncharacters at arbitrary locations within a sequence, with no need for\napproximate sampling methods. Despite the sequential architecture of u-MPS, we\nshow that a recursive evaluation algorithm can be used to parallelize its\ninference and training, with a string of length n only requiring parallel time\n$\\mathcal{O}(\\log n)$ to evaluate. Experiments on a context-free language\ndemonstrate a strong capacity to learn grammatical structure from limited data,\npointing towards the potential of tensor networks for language modeling\napplications.\n</blockquote>", "abstract_text": "  The tensor network formalism has enjoyed over two decades of success in\nmodeling the behavior of complex quantum-mechanical systems, but has only\nrecently and sporadically been leveraged in machine learning. Here we introduce\na uniform matrix product state (u-MPS) model for probabilistic modeling of\nsequence data. We identify several distinctive features of this recurrent\ngenerative model, notably the ability to condition or marginalize sampling on\ncharacters at arbitrary locations within a sequence, with no need for\napproximate sampling methods. Despite the sequential architecture of u-MPS, we\nshow that a recursive evaluation algorithm can be used to parallelize its\ninference and training, with a string of length n only requiring parallel time\n$\\mathcal{O}(\\log n)$ to evaluate. Experiments on a context-free language\ndemonstrate a strong capacity to learn grammatical structure from limited data,\npointing towards the potential of tensor networks for language modeling\napplications.\n"},
    {"title": "A Least-Squares Formulation of the Moving Discontinuous Galerkin Finite Element Method with Interface Condition Enforcement", "submission_date": "Mon, 2 Mar 2020 17:22:38 UTC", "authors": ["Andrew D. Kercher", "Andrew Corrigan"], "pdf_link": "https://arxiv.org/pdf/2003.01044.pdf", "abstract": "<blockquote class=\"abstract mathjax\"><span class=\"descriptor\">Abstract:</span>  A least-squares formulation of the Moving Discontinuous Galerkin Finite\nElement Method with Interface Condition Enforcement (LS-MDG-ICE) is presented.\nThis method combines MDG-ICE, which uses a weak formulation that separately\nenforces a conservation law and the corresponding interface condition and\ntreats the discrete geometry as a variable, with the Discontinuous\nPetrov-Galerkin (DPG) methodology of Demkowicz and Gopalakrishnan to\nsystematically generate optimal test functions from the trial spaces of both\nthe discrete flow field and discrete geometry. For inviscid flows, LS-MDG-ICE\ndetects and fits a priori unknown interfaces, including shocks. For\nconvection-dominated diffusion, LS-MDG-ICE resolves internal layers, e.g.,\nviscous shocks, and boundary layers using anisotropic curvilinear\n$r$-adaptivity in which high-order shape representations are anisotropically\nadapted to accurately resolve the flow field. As such, LS-MDG-ICE solutions are\noscillation-free, regardless of the grid resolution and polynomial degree.\nFinally, for both linear and nonlinear problems in one dimension, LS-MDG-ICE is\nshown to achieve optimal convergence of the $L^2$ solution error with respect\nto the exact solution when the discrete geometry is fixed and super-optimal\nconvergence when the discrete geometry is treated as a variable.\n</blockquote>", "abstract_text": "  A least-squares formulation of the Moving Discontinuous Galerkin Finite\nElement Method with Interface Condition Enforcement (LS-MDG-ICE) is presented.\nThis method combines MDG-ICE, which uses a weak formulation that separately\nenforces a conservation law and the corresponding interface condition and\ntreats the discrete geometry as a variable, with the Discontinuous\nPetrov-Galerkin (DPG) methodology of Demkowicz and Gopalakrishnan to\nsystematically generate optimal test functions from the trial spaces of both\nthe discrete flow field and discrete geometry. For inviscid flows, LS-MDG-ICE\ndetects and fits a priori unknown interfaces, including shocks. For\nconvection-dominated diffusion, LS-MDG-ICE resolves internal layers, e.g.,\nviscous shocks, and boundary layers using anisotropic curvilinear\n$r$-adaptivity in which high-order shape representations are anisotropically\nadapted to accurately resolve the flow field. As such, LS-MDG-ICE solutions are\noscillation-free, regardless of the grid resolution and polynomial degree.\nFinally, for both linear and nonlinear problems in one dimension, LS-MDG-ICE is\nshown to achieve optimal convergence of the $L^2$ solution error with respect\nto the exact solution when the discrete geometry is fixed and super-optimal\nconvergence when the discrete geometry is treated as a variable.\n"},
    {"title": "Double Trouble in Double Descent : Bias and Variance(s) in the Lazy Regime", "submission_date": "Mon, 2 Mar 2020 17:39:31 UTC", "authors": ["St\u00e9phane d'Ascoli", "Maria Refinetti", "Giulio Biroli", "Florent Krzakala"], "pdf_link": "https://arxiv.org/pdf/2003.01054.pdf", "abstract": "<blockquote class=\"abstract mathjax\"><span class=\"descriptor\">Abstract:</span>  Deep neural networks can achieve remarkable generalization performances while\ninterpolating the training data perfectly. Rather than the U-curve emblematic\nof the bias-variance trade-off, their test error often follows a double descent\n- a mark of the beneficial role of overparametrization. In this work, we\ndevelop a quantitative theory for this phenomenon in the so-called lazy\nlearning regime of neural networks, by considering the problem of learning a\nhigh-dimensional function with random features regression. We obtain a precise\nasymptotic expression for the bias-variance decomposition of the test error,\nand show that the bias displays a phase transition at the interpolation\nthreshold, beyond it which it remains constant. We disentangle the variances\nstemming from the sampling of the dataset, from the additive noise corrupting\nthe labels, and from the initialization of the weights. Following Geiger et\nal., we first show that the latter two contributions are the crux of the double\ndescent: they lead to the overfitting peak at the interpolation threshold and\nto the decay of the test error upon overparametrization. We then quantify how\nthey are suppressed by ensembling the outputs of K independently initialized\nestimators. When K is sent to infinity, the test error remains constant beyond\nthe interpolation threshold. We further compare the effects of\noverparametrizing, ensembling and regularizing. Finally, we present numerical\nexperiments on classic deep learning setups to show that our results hold\nqualitatively in realistic lazy learning scenarios.\n</blockquote>", "abstract_text": "  Deep neural networks can achieve remarkable generalization performances while\ninterpolating the training data perfectly. Rather than the U-curve emblematic\nof the bias-variance trade-off, their test error often follows a double descent\n- a mark of the beneficial role of overparametrization. In this work, we\ndevelop a quantitative theory for this phenomenon in the so-called lazy\nlearning regime of neural networks, by considering the problem of learning a\nhigh-dimensional function with random features regression. We obtain a precise\nasymptotic expression for the bias-variance decomposition of the test error,\nand show that the bias displays a phase transition at the interpolation\nthreshold, beyond it which it remains constant. We disentangle the variances\nstemming from the sampling of the dataset, from the additive noise corrupting\nthe labels, and from the initialization of the weights. Following Geiger et\nal., we first show that the latter two contributions are the crux of the double\ndescent: they lead to the overfitting peak at the interpolation threshold and\nto the decay of the test error upon overparametrization. We then quantify how\nthey are suppressed by ensembling the outputs of K independently initialized\nestimators. When K is sent to infinity, the test error remains constant beyond\nthe interpolation threshold. We further compare the effects of\noverparametrizing, ensembling and regularizing. Finally, we present numerical\nexperiments on classic deep learning setups to show that our results hold\nqualitatively in realistic lazy learning scenarios.\n"}
    ]